{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть две идеи:\n",
    "### 1-ая идея:\n",
    "\n",
    "- Обучение:\n",
    "Вытащить из корпуса все positive / negative слова\n",
    "Векторизовать каждое слово с помощью word2vec\n",
    "Написать простой классификатор (вектор - класс)\n",
    "\n",
    "- Тестирование:\n",
    "На вход поступает слово\n",
    "Вектурезуем его с помощью word2vec и делаем predict\n",
    "\n",
    "\n",
    "### 2-ая идея\n",
    "\n",
    "- Обучение\n",
    "Подать на word2vec сначала негативные слова, векторизовать, записать в массив. \n",
    "Потом подать на word2vec позитивные, векторизовать. \n",
    "Получится два облака.\n",
    "\n",
    "- Тестирование\n",
    "Далее входные слова сравнивать с каждым из этих двух облаков.\n",
    "Берем входное слово, сравниваем его с каждым словом из позитивного облака, запиисываем расстояние. \n",
    "Потом сравниваем с каждым словом из негативного облака и тоже считаем расстояние. \n",
    "Сравниваем результаты по расстояниям по разным облакам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import division\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lxml import etree\n",
    "\n",
    "import pymorphy2\n",
    "import math\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from stop_words import get_stop_words\n",
    "\n",
    "from text_cleanisation_NLP import text_to_words\n",
    "import gensim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from sklearn import cross_validation\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "\n",
    "RUS_LETTERS = u'абвгдеёжзийклмнопрстуфхцчшщъыьэюя'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_xml(filename):\n",
    "    with open(filename, encoding='utf-8') as f:\n",
    "        xml = f.read()\n",
    "\n",
    "    dict = {}\n",
    "    text = []\n",
    "    category = []\n",
    "    sentiment = []\n",
    "    term = []\n",
    "\n",
    "    root = etree.fromstring(xml)\n",
    "    for child in root:\n",
    "        for aspect in child[3]:\n",
    "            if aspect.attrib['type'] == 'implicit' and aspect.attrib['sentiment']!= 'both' and aspect.attrib['sentiment']!= 'neutral':\n",
    "                text.append(child[2].text)\n",
    "                category.append(aspect.attrib['category'])\n",
    "                sentiment.append(aspect.attrib['sentiment'])\n",
    "                term.append(aspect.attrib['term'])\n",
    "\n",
    "    dict['text'] = text\n",
    "    dict['category'] = category\n",
    "    dict['sentiment'] = sentiment\n",
    "    dict['term'] = term\n",
    "\n",
    "    \n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_train = parse_xml('SentiRuEval_rest_markup_train.xml')\n",
    "text_test = parse_xml('SentiRuEval_rest_markup_test.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(text_train)\n",
    "df2 = pd.DataFrame(text_test)\n",
    "\n",
    "frames = [df1, df2]\n",
    "df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>term</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Food</td>\n",
       "      <td>positive</td>\n",
       "      <td>вкусное</td>\n",
       "      <td>День 8-го марта прошёл, можно и итоги подвести...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Interior</td>\n",
       "      <td>positive</td>\n",
       "      <td>уютный</td>\n",
       "      <td>День 8-го марта прошёл, можно и итоги подвести...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Food</td>\n",
       "      <td>positive</td>\n",
       "      <td>вкусные</td>\n",
       "      <td>Отмечали в этом ресторане день рождение на пер...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Interior</td>\n",
       "      <td>positive</td>\n",
       "      <td>уютно</td>\n",
       "      <td>Отмечали в этом ресторане день рождение на пер...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Interior</td>\n",
       "      <td>positive</td>\n",
       "      <td>красиво</td>\n",
       "      <td>Отмечали в этом ресторане день рождение на пер...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category sentiment     term  \\\n",
       "0      Food  positive  вкусное   \n",
       "1  Interior  positive   уютный   \n",
       "2      Food  positive  вкусные   \n",
       "3  Interior  positive    уютно   \n",
       "4  Interior  positive  красиво   \n",
       "\n",
       "                                                text  \n",
       "0  День 8-го марта прошёл, можно и итоги подвести...  \n",
       "1  День 8-го марта прошёл, можно и итоги подвести...  \n",
       "2  Отмечали в этом ресторане день рождение на пер...  \n",
       "3  Отмечали в этом ресторане день рождение на пер...  \n",
       "4  Отмечали в этом ресторане день рождение на пер...  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>term</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1367</td>\n",
       "      <td>1367</td>\n",
       "      <td>1367</td>\n",
       "      <td>1367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>505</td>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Food</td>\n",
       "      <td>positive</td>\n",
       "      <td>вкусно</td>\n",
       "      <td>Отмечали свадьбу 15 марта. Ах-Ах!!! Замечатель...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>538</td>\n",
       "      <td>1235</td>\n",
       "      <td>137</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       category sentiment    term  \\\n",
       "count      1367      1367    1367   \n",
       "unique        5         2     505   \n",
       "top        Food  positive  вкусно   \n",
       "freq        538      1235     137   \n",
       "\n",
       "                                                     text  \n",
       "count                                                1367  \n",
       "unique                                                371  \n",
       "top     Отмечали свадьбу 15 марта. Ах-Ах!!! Замечатель...  \n",
       "freq                                                   14  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>term</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">negative</th>\n",
       "      <th>count</th>\n",
       "      <td>132</td>\n",
       "      <td>132</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5</td>\n",
       "      <td>105</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Food</td>\n",
       "      <td>дорого</td>\n",
       "      <td>Посещали это заведение 2 раза, ощущения разные...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>54</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">positive</th>\n",
       "      <th>count</th>\n",
       "      <td>1235</td>\n",
       "      <td>1235</td>\n",
       "      <td>1235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5</td>\n",
       "      <td>402</td>\n",
       "      <td>353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Food</td>\n",
       "      <td>вкусно</td>\n",
       "      <td>Отмечали свадьбу 15 марта. Ах-Ах!!! Замечатель...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>484</td>\n",
       "      <td>137</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 category    term  \\\n",
       "sentiment                           \n",
       "negative  count       132     132   \n",
       "          unique        5     105   \n",
       "          top        Food  дорого   \n",
       "          freq         54       5   \n",
       "positive  count      1235    1235   \n",
       "          unique        5     402   \n",
       "          top        Food  вкусно   \n",
       "          freq        484     137   \n",
       "\n",
       "                                                               text  \n",
       "sentiment                                                            \n",
       "negative  count                                                 132  \n",
       "          unique                                                 91  \n",
       "          top     Посещали это заведение 2 раза, ощущения разные...  \n",
       "          freq                                                    4  \n",
       "positive  count                                                1235  \n",
       "          unique                                                353  \n",
       "          top     Отмечали свадьбу 15 марта. Ах-Ах!!! Замечатель...  \n",
       "          freq                                                   14  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('sentiment').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сделаем датасет сбалансированным\n"
     ]
    }
   ],
   "source": [
    "print('Сделаем датасет сбалансированным')\n",
    "df = pd.concat([df[df['sentiment'] == 'positive'].sample(frac=1)[:132], df[df['sentiment'] == 'negative']]).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Загрузим модель\n",
    "m = 'ruscorpora_1_300_10.bin'\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(m, binary=True)\n",
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transit = {'ADJF':'ADJ', 'INFN':'VERB', 'ADVB':'ADV'}\n",
    "robj = re.compile('|'.join(transit.keys()))\n",
    "\n",
    "def cleanization(text):\n",
    "    for line in text:\n",
    "        # 1. Все буквы в нижний регистр\n",
    "        text_text = text.lower()\n",
    "\n",
    "        # 2. Удаление всех небукв\n",
    "        letters_only = ''\n",
    "        for _c in text_text:\n",
    "            if _c in RUS_LETTERS:\n",
    "                letters_only += _c\n",
    "            else:\n",
    "                letters_only += ' '\n",
    "\n",
    "        # 3. Заменяем множественные пробелы\n",
    "        while '  ' in letters_only:\n",
    "            letters_only = letters_only.replace('  ', ' ')\n",
    "\n",
    "        # 4. Токенизация\n",
    "        word_list = tokenizer.tokenize(letters_only)\n",
    "\n",
    "        # 5. Лемматизация\n",
    "        clean_word_list = [morph.parse(word)[0].normal_form for word in word_list]  # лемматизация\n",
    "    \n",
    "        # 6. Удаление стоп-слов + добавление тегов - части речи\n",
    "        meaningful_words = [str(word) + '_' + robj.sub(lambda m: transit[m.group(0)], str(morph.parse(word)[0].tag.POS)) for word in clean_word_list if word not in get_stop_words('ru')] # стоп-слова\n",
    "        return ' '.join(meaningful_words)   # meaningful_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "def mean(a):\n",
    "    return sum(a) / len(a)\n",
    "\n",
    "\n",
    "# def numbers(text):\n",
    "#     \"\"\"Усредняет вектор слов.\"\"\"\n",
    "#     arr = []\n",
    "#     clean_text = cleanization(text)\n",
    "#     # для каждого слова в тексте выводим его вектор\n",
    "#     for word in clean_text.split():\n",
    "#     # есть ли слово в модели? Может быть, и нет\n",
    "#         if word in model:\n",
    "#             arr.append(model[word])\n",
    "#     # print(len(list(map(mean, zip(*arr)))))\n",
    "#     return list(map(mean, zip(*arr)))\n",
    "\n",
    "def numbers(text):\n",
    "    \"\"\"Усредняет вектор слов.\"\"\"\n",
    "    arr = []\n",
    "    clean_text = cleanization(text)\n",
    "    # для каждого слова в тексте выводим его вектор\n",
    "    for word in clean_text.split():\n",
    "    # есть ли слово в модели? Может быть, и нет\n",
    "        if word in model:\n",
    "            arr.append(model[word])\n",
    "    if len(list(map(mean, zip(*arr)))) != 0:\n",
    "        return list(map(mean, zip(*arr)))\n",
    "    else:\n",
    "        return [0 for i in range(0, 300)]\n",
    "\n",
    "# В функции надо указать, что делать с вектором, если не нашлось слова в моделе\n",
    "\n",
    "\n",
    "class FunctionFeaturizer(TransformerMixin):\n",
    "    \"\"\" Для создания своего вектора я использовала несколько фич: длину текста, количество заглавных букв\n",
    "     (чем больше, тем обычно выше вероятность, что это спам), количество ! (в спам-сообщениях встречаются часто),\n",
    "     количество чисел, сколько слов из словаря спам-слов (50 самых частых слов в коллекции спам-сообщений)\"\"\"\n",
    "    def __init__(self, featurizers):\n",
    "        self.featurizers = featurizers\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        fvs = []\n",
    "        for datum in X:\n",
    "            fv = numbers(datum)\n",
    "            fvs.append(fv)\n",
    "        return np.array(fvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['term'], df['sentiment'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "329         жесткое\n",
       "494    пересоленная\n",
       "664       улыбчивая\n",
       "495     заветренные\n",
       "288    по-домашнему\n",
       "Name: term, dtype: object"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "329    negative\n",
       "494    negative\n",
       "664    positive\n",
       "495    negative\n",
       "288    positive\n",
       "Name: sentiment, dtype: object"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count        211\n",
       "unique       150\n",
       "top       вкусно\n",
       "freq          17\n",
       "Name: term, dtype: object"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_smth_with_model(data_train, class_train, data_test, class_test, steps):\n",
    "    print('\\nModel train')\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "\n",
    "    cv_results = cross_val_score(pipeline,\n",
    "                                 data_train,\n",
    "                                 class_train,\n",
    "                                 cv=10,\n",
    "                                 scoring='accuracy',\n",
    "                                )\n",
    "    print(cv_results.mean(), cv_results.std())\n",
    "\n",
    "    pipeline.fit(data_train, class_train)\n",
    "    class_predicted = pipeline.predict(data_test)\n",
    "    print(class_predicted)\n",
    "\n",
    "    print(classification_report(class_test, class_predicted ))\n",
    "\n",
    "    return pipeline, class_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w2v_featurizer = FunctionFeaturizer(numbers)  # создание своего векторизатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Custom Transformer\n",
      "\n",
      "Model train\n",
      "0.886363636364 0.0677682779414\n",
      "['negative' 'negative' 'positive' 'negative' 'positive' 'positive'\n",
      " 'positive' 'negative' 'positive' 'negative' 'negative' 'positive'\n",
      " 'negative' 'positive' 'negative' 'positive' 'negative' 'negative'\n",
      " 'positive' 'positive' 'positive' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'positive' 'positive' 'negative' 'positive'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'positive' 'negative' 'negative'\n",
      " 'negative' 'positive' 'positive' 'positive' 'positive' 'negative'\n",
      " 'positive' 'positive' 'positive' 'positive' 'negative']\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.93      0.90      0.92        31\n",
      "   positive       0.87      0.91      0.89        22\n",
      "\n",
      "avg / total       0.91      0.91      0.91        53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Свой векторизатор\n",
    "print('\\nCustom Transformer')\n",
    "pipeline, label_predicted = do_smth_with_model(X_train, y_train,\n",
    "                                               X_test, y_test, \n",
    "                                               steps=[('custom', w2v_featurizer),\n",
    "                                                      ('classifier', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Custom Transformer\n",
      "\n",
      "Model train\n",
      "0.816017316017 0.126021621154\n",
      "['positive' 'negative' 'negative' 'negative' 'positive' 'positive'\n",
      " 'positive' 'negative' 'positive' 'negative' 'negative' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'negative' 'negative'\n",
      " 'positive' 'positive' 'positive' 'negative' 'positive' 'negative'\n",
      " 'positive' 'negative' 'positive' 'positive' 'negative' 'positive'\n",
      " 'negative' 'negative' 'negative' 'positive' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'positive' 'negative' 'negative'\n",
      " 'negative' 'positive' 'positive' 'positive' 'positive' 'negative'\n",
      " 'positive' 'positive' 'positive' 'positive' 'negative']\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.92      0.74      0.82        31\n",
      "   positive       0.71      0.91      0.80        22\n",
      "\n",
      "avg / total       0.83      0.81      0.81        53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Свой векторизатор\n",
    "print('\\nCustom Transformer')\n",
    "pipeline, label_predicted = do_smth_with_model(X_train, y_train,\n",
    "                                               X_test, y_test, \n",
    "                                               steps=[('custom', w2v_featurizer),\n",
    "                                                      ('classifier', ExtraTreesClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Сделать дата сет сбалансированным, предварительно смешав вместе с тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Custom Transformer\n",
      "\n",
      "Model train\n",
      "0.886363636364 0.0677682779414\n",
      "['negative' 'negative' 'positive' 'negative' 'positive' 'positive'\n",
      " 'positive' 'negative' 'positive' 'negative' 'negative' 'positive'\n",
      " 'negative' 'positive' 'negative' 'positive' 'negative' 'negative'\n",
      " 'positive' 'positive' 'positive' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'positive' 'positive' 'negative' 'positive'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'positive' 'negative' 'negative'\n",
      " 'negative' 'positive' 'positive' 'positive' 'positive' 'negative'\n",
      " 'positive' 'positive' 'positive' 'positive' 'negative']\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.93      0.90      0.92        31\n",
      "   positive       0.87      0.91      0.89        22\n",
      "\n",
      "avg / total       0.91      0.91      0.91        53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Свой векторизатор\n",
    "print('\\nCustom Transformer')\n",
    "pipeline, label_predicted = do_smth_with_model(X_train, y_train,\n",
    "                                               X_test, y_test, \n",
    "                                               steps=[('custom', w2v_featurizer),\n",
    "                                                      ('classifier', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
